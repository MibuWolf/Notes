---
tags:
  - ue unreal metahuman
---

# 1. 概述

UE 的Metahuman面世了已经有相当一段多时间了，各路的分析文章已有不少，但是目前为止就我个人的使用经验而言，这些文章读起来还是有点吃力的，俗话说得好，实践是检验真理的唯一标准，我个人对metahuman的学习和掌握还是依靠亲自去跑一遍这个管线，同时读了官方的文档以后，然后才对metahuman的技术有一个比较深的理解。

客观的说，metahuman离元宇宙随意捏人的标准，也就是我们所谓的自由王国还是由相当大的距离的，但是这个工具已经的确是一种现阶段能大力提升效率的一种手段。如果正确的使用，可以给大家各自的工程提升相当大的智人类角色的开发速率，我个人感觉这个周期大概是在4个月压缩到0.5个月左右。也就是说，我们可以期待8倍的速率的提升（前提是不对metahuman本身进行各种大规模深度改编）

本文的面向的读者，主要是游戏策划和各种角色/NPC的策划，角色美术，以及动画TA。因为我们是以工具的手段去看待Metahuman的。中国工业界普遍有一些敝帚自珍的习惯，缺乏信息和资源的快速流通和共享，这非常不适合IT工业需要大量新鲜教程不停带动社区进步的需求。因此，本文将力图以最简单的语言，尽可能全面的解说什么是Metahuman ，以及怎么把metahuman给用起来。最后是，依托Houdini的KineFX角色/动画工具集，怎么暴改Metahuman以使我们提高临摹性质的角色建模速度。

当然，由于Metahuman所涉及的上下游技术实在是太过于宽广，本文并不能顾及到Metahuman所有的技术点，因此不足之处还请见谅指正。

本文力图做到不需要太深的虚幻引擎的基础知识就能使用Metahuman。当然有一点最好，如果还有一点DCC软件的基础知识就更好了。

# 2. 什么是MetaHuman

# 2.1 MetaHuman是一个次世代角色和动画模板

用一句话说：Metahuman就是一个虚幻引擎的人类（智人）角色的Skeletal Mesh骨骼模型的模板。他和我们在UE商城里看到的Paragon角色，甚至和我们在UE引擎里搞的角色没有本质差别。

上面那个是概括。Metahuman的体系结构如下图所示（可以右击选择在新页面中打开来放大）。

![[UnrealEngine/MetaHuman/attachments/Pic_001.png]]

- 在Metahuman的最核心部位是一个标准化的UE 人类的头部和身体（含部分身体）的骨骼模型（Skeletal Mesh Asset）资产，这是Metahuman可以起作用的做小范畴。
- 在第二层，通过Metahuman的官方材质和物理资产，我们可以让Metahuman呈现真实的视觉观感，同时支持其自己的毛发和身体的交互（在整个关卡中只有Metahuman一个Mesh对象的情况下）。
- 在第三层，是虚幻引擎提供的动画工具，它可以在引擎内就制作出Metahuman的面部和身体动画。传统的管线中，我们必须依赖MAYA/MAX等软件完成骨骼动画的制作
- 到了第四层，则是引擎的支持工具，这包括了Metahumna角色蓝图和Groom毛发，缺乏这两个东西，角色将变成不能活动的标本。
- 最外面一层是面向策划的，Epic官方提供了一些创建Metahuman角色的工具，通过这些工具可以以很小的成本创建栩栩如生的PBR 3A级别的人类角色

## 2.2 MetaHuman有什么进步？

Metahuman的技术进步主要可以分为两点：

### 2.2.1 建模管线的进步

传统的人类角色建模并不是一件很容易的事情，人体表面的复杂曲线非常难以把握，建模师需要具备相当的美术，医学和解剖方面的细节去把握人体模型的大体和细节。一方面这些细节用于还原人体的几何形状，另一方面这些细节知识需要支撑当人体模型变形的时候去尽量逼近现实中的人类肉体形变。最后，这些细节知识被用于创建人体的贴图和制作着色器shader（也就是常说的材质球）。这样一来，传统的3A级别质量，采用写实类美术风格的人类角色就相当昂贵了。从策划开始寻找素材，再到原画师开始画画，再到建模师用Poly拉起角色的大型，再到雕刻软件的雕琢角色肌肉和骨骼细节，再到TA开始建立骨骼，绑定，精细修整Mesh的骨骼权重，创建Morph变形对象，再到美术师去制作角色贴图，创建角色的材质，这样一个流程使我们增加任何一个人类角色都将增加非常昂贵的代价。

特别是在有些开发团队中，策划甚至资方经常喜欢改需求，有的时候往往是走到了最后一步画完贴图，开始精细调整角色皮肤shader了，策划改角色的需求来了。有的时候，一些加性的需求可以hack，但是有的时候那些减性乃至非线性的需求则是毁灭性的——整个流程将会倒退回原画到建模左右的节点。这个流程可以直接让进度出现3个月以上的倒退，其经济成本不可谓不大。

Metahuman技术在其支持的范畴内，可以支持对角色进行一定的修改，并且修改后的结果可以立即被返回给项目（相对于传统的月级别的返工，Metahuman在半天到一天左右的返工时间可谓说已经相当快了）。因此这是一大进步。

![[UnrealEngine/MetaHuman/attachments/Pic_002.png]]

如果我们metahuman的角色制作管线和传统的工艺对比，我们会发现Metahuman简直是一个巨大Hack——因为Metahuman几乎跳过了所有繁琐的评估会议和角色的拓扑/美术制作环节。依靠一套非常精细的模板和一些智能系统，Metahuman可以直接让策划得到它想要的角色。

### 2.2.2 面部动画管线的进步

传统的面部动画可谓是3A游戏的豪华配置，不是一些小团队和Indie团队能负担的起的。如果不用面部捕捉技术的话，那么手动雕刻面部变形细节，大约也需要数百个变形结果才能达到3A级别的要求。在影视项目中，这个数据可以达到8000（玩具总动员，没错，玩具总动员就是用的Morph大法），甚至过万。理论上说，面部动画可以用面部骨骼点驱动，但是面部骨骼点之密集，使刷面部权重也变成了一项难度间距的任务，而面部骨骼的动画制作更是难上加难，在如此密集的骨骼点中挑选想要拖动的骨骼，完全是一种不人道的动画制作模式。更何况，当这一切开始叠加时间线时，任务的复杂度又会提升一个数量级。而如果采用面部捕捉技术，也不会让工作轻松太多，首先就是要寻找面捕演员，合格的面捕演员中还需要挑选面部形态接近的，然后还需要面捕棚的参与，这首先是一笔对于中小团队来说难以接受的开销。而Metahuman则是通过预设了非常精细的面部骨骼和Morph对象，另外提供了UE的Livelink技术，一下子把面部捕捉的管线提升为了视频AI面捕，这样一个进步直接把面捕的成本打到了地板价。

# 3. 如何上手MetaHuman？

## 3.1 先解决Metahuman角色创建的问题

大家应该已经听说过一些关于利用Metahuman把自己扫描上传然后做一个自己的永生数字人的邪术。

![[UnrealEngine/MetaHuman/attachments/Pic_003.png]]

But，作为新手，我们还是先忘掉这回事情，这不是我们一开始能涉及的范畴。我们还是按照官方的文档，来先认识一下常规的Metahuman角色是怎么制作的。

### Step1. 用浏览器登录Epic Metahuman Creator，在web端常见metahuman角色

打开[MetaHuman | Realistic Person Creator - Unreal Engine](https://www.unrealengine.com/en-US/metahuman)这个网址。

![[UnrealEngine/MetaHuman/attachments/Pic_004.png]]

进去以后应该首先选择对应的UE引擎版本：注意你只能选择和你的引擎版本匹配的Metahuman Creator，否则quixel里将会无法找到你的角色.从来没有使用过Metahuman的Epic账号首先需要请求Early Access（因为这个产品截止2023年还在测试中），然后点击右面那个按钮打开Web端的Metahuman Creator一开始你看到的应该是已经创建的Metahuman角色，而新账号可以直接点击屏幕左上角的Create按钮进入Metahuman创建页面。

Metahuman Web应用目前只支持非常有限的角色形态编辑，头部目前可以进行脸型混合和几个粗大的面部线条编辑。其次是眼部，眉毛，牙齿的编辑，然后是体型的编辑。注意体型只能在三个身高档次中，分别选自各自身高级别的男女角色身体，以及各自的消瘦，正常，肥胖三个体重。也就是上总共是3*2*3=18个身体Mesh。

下面这个视频是MetahumanCreator编辑器的简短介绍：[External Player - 哔哩哔哩嵌入式外链播放器 (bilibili.com)](https://player.bilibili.com/player.html?aid=756695088&bvid=BV1Pr4y1N7ef&cid=295848896&page=1&high_quality=1)此外还有如下视频：

![[Video_003.mp4]]

下面这个视频就是事无巨细版，有需要的同学可以观看：

![[Video_004.mp4]]

### Step2. 安装Quixel插件

（已经安装过的可以跳过此步骤）
在UE5.0版本以后，Quixel Bridge已经以插件的形式登录UE引擎本体，我们可以直接在UE编辑器顶部的Edit菜单-Plugins菜单里面直接启用即可。

![[UnrealEngine/MetaHuman/attachments/Pic_005.png]]

### Step3. 打开UE引擎，用登录Metahuman Creator的账号登录UE的Quixel插件，下载自己的数字人

![[Video_002.mp4]]

## 3.2 Metahuman的文件夹结构解析

当大家第一次打开Metahuman的文件夹，可能被里面复杂的文件结构给吓一跳。这是很正常的，Epic的确把Metahuman及其角色蓝图的功能组件和美术资产散落在各个不同的文件夹里面，使整个系统看起来比较混乱。

但是不用着急。接下来我们就会讲解一下Metahuman的文件结构是怎样的

### 首先，我们来关注根目录下的Common文件夹

这个文件夹里我们只要重点关注三个子文件夹

![[UnrealEngine/MetaHuman/attachments/Pic_006.png]]

**Common：**这里存放的是Metahuman角色的标准化面部动作库和Metahuman标准身体的动画控制组件。其中包括了Metahuman身体骨骼的标准动画蓝图以及其ControlRig控制器，以及用于Metahuman标准骨骼重定向的各种资源。

![[UnrealEngine/MetaHuman/attachments/Pic_007.png]]

**Face：**这里存放的是Metahuman的标准面部骨骼模型，以及面部标准骨骼，以及面部标准骨骼的动画蓝图，以及应用于面部标准骨骼的control rig控制器 （常用的有两套控制器，调节板控制器和简易控制器）。注意这里的Face_Archetype和Face_Archetype_Skeleton就是所有Metahuman共享的一个头部模型（骨骼）规范，如果我们自定义的头部不使用这个东西是没办法使用Metahuman自己的control rig乃至面部动画的

![[UnrealEngine/MetaHuman/attachments/Pic_008.png]]

**Female:**（服务于男性角色则是Male菜单，他们的内部结构是等价的，因此归于一类）：这里存放的是两种性别不同身高-体重角色的标准身体模型，以及他们的动画蓝图，物理属性资产和标准骨骼。注意这个文件夹里就是该性别下各个身高，体重模板下的标准身体骨骼模型及其对应的骨骼，还有动画蓝图。还有他们共享的贴图——如果我们不改变角色皮肤细节的话，那么使用相同皮肤细节角色会共享Cavity和Normal贴图。此外这个文件夹会存放角色衣服。由于Metahuman的角色之间是共享身体的，所以其衣服的Mesh也是共享的，而各个角色的衣服的材质则是各自独立拥有的。

![[UnrealEngine/MetaHuman/attachments/Pic_009.png]]
![[UnrealEngine/MetaHuman/attachments/Pic_010.png]]
![[UnrealEngine/MetaHuman/attachments/Pic_011.png]]

### 接下来，我们来分析每个独立的Metahuman角色自己的目录

我们也只需要重点关注几个目录

![[UnrealEngine/MetaHuman/attachments/Pic_012.png]]

**Body**：里面存放的是角色完整的身体的Basecolor也就是漫反射颜色贴图

![[UnrealEngine/MetaHuman/attachments/Pic_013.png]]

**Face**：这里存放的是重点：每个角色各自的面部/头部的模型，贴图和材质，同时也包含眼睛的材质。这是实现Metahuman千人千面的关键。多个Metahuman角色会使用不同的头部模型，插在相同的身体模型上。

![[UnrealEngine/MetaHuman/attachments/Pic_014.png]]

**Female**：这里存放的是被裁剪的角色身体。当我们在Metahuman Creator给角色添加衣服以后，那么游戏会为我们提供一个“将被衣服遮住的部位裁减掉的”身体模型，大家可以看见这个模型是只露出手臂和腿部的。

![[UnrealEngine/MetaHuman/attachments/Pic_015.png]]

![[UnrealEngine/MetaHuman/attachments/Pic_016.png]]

至于剩下的那些目录没有必要第一次就了解清楚，大家在使用角色过程中自然而然的会接触到的。

# 4. 逐级解析Metahuman系统

## 4.1 Metahuman核心Skeletal Mesh骨骼模型资产

我们可以直接打开Metahuman-Common-Female（Male）-Medium-NormalWeight-Body目录

![[UnrealEngine/MetaHuman/attachments/Pic_017.png]]

首先进去检查Metahuman_base_skel，也就是所有Metahuman共通的身体骨骼

![[UnrealEngine/MetaHuman/attachments/Pic_018.png]]

可以看到这是一个拥有者将近300个骨骼点的复杂骨骼结构，他不仅对手指做了绑定，对四肢还做了额外的扭曲修正的骨骼点设定。为了看清楚身体骨骼模型的更多信息，我们将其导出给Houdini

![[UnrealEngine/MetaHuman/attachments/Pic_019.png]]

我们可以看到，确实Metahuman角色的身体模型是不含头部的一个“底座”模型，UE Metahuman的角色实现机制就是把一个又一个人头给扣在这类底座上。

![[UnrealEngine/MetaHuman/attachments/Pic_020.png]]

这个作为底座的身体模型的UV非常有意思，它的UV被放置在了正常的UV区间以外，很显然，这是因为Metahuman本来是想支持UDIM材质的。这样头部和身体实际上可以共用一个UDIM贴图，一个材质球。只不过是因为现在的技术还做不到所以头部单独拿出来做了。但是我们已经可以在这个基础上就行修改了。

## 4.2 Metahuman物理/视觉资产

### 4.2.1 物理资产

Epic已经为我们准备好了一个metahuman的默认物理资产，存放的位置是Content\Metahumans\Common\Female(Male)\XXX(身高)\yyy(体重)\Body下面
例如我们这个高个子的瘦子的骨骼模型的物理资产

![[UnrealEngine/MetaHuman/attachments/Pic_021.png]]

目前物理资产唯一的作用就是辅助各种物理效果的运算，更精确一点来说就是支持角色布料/服装的效果。有兴趣的同学可以在这个视频里更详细的了解UE5默认的chaos布料交互。[Unreal Engine 5 Cloth Simulation - For Characters - YouTube](https://www.youtube.com/watch?v=zXjpX-SirM0&t=1062s)

对于复杂而精密的服装模型，UE采用了一种简化运算的套路，即采用相同形状更低poly数量的proxy mesh（近似网格）去模拟运动，再把位置传递给复杂的渲染mesh，而proxy mesh则在游戏渲染中被剔除（proxy mesh需要我们自己在DCC里面准备，我们的权重会刷在proxy mesh上面，然后我们手动disable proxy mesh的材质组）。需要注意的是UE5默认的chaos布料交互不太适合紧身衣的模拟，更适合那些宽大的披风类型的模拟。

### 4.2.2 视觉资产——头部材质

metahuman的视觉资产即默认的材质系统。
我们先从mesh头部的材质讲起。需要说明的是，metahuman的材质球内部非常复杂，官方也不建议我们对其进行魔改。但是这并不妨碍我们分析一下它的技术原理（但我偏要）。头部的材质默认是材质的实例，其所依赖的材质蓝图在Content/MetaHumans/Common/Face/Materials/Baked/M_Head_Baked.uasset这里。

![[UnrealEngine/MetaHuman/attachments/Pic_022.png]]

(这张shader graph甚至已经庞大到了缩放到最大比例都无法完整展示其面貌的程度了)。

首先我们要认识到，metahuman头部的材质球是通过预先就做好的basecolor和normal两个通道的多套贴图驱动的。每个metahuman角色会存储<基本颜色>和<法线>通道各自默认拥有四个不同的贴图变种，这四种不同的贴图会通过角色表情驱动其在初级混合部分的比重。因此，metahuman的材质是拥有动画效果的。如果大家没有理解上面的话也不用担心，我再用通俗的语言解释一下：由于角色面部需要支持各种不同的表情，比方说“_害羞时脸红，发怒时脸黑_”，这些不同的表情除了要求面部肌肉和皮肤要有变化，还要求_面部的颜色（也就是材质）也发生变化_。而材质信息毕竟是无定式规范的数据，不能像骨骼变换那样进行动画，所以我们_预先准备好了脸红时脸黑时或者其他面部外观的漫反射和法线贴图_，等到角色开始执行表情的时候，这个表情的权重参数就会通过一些接口去影响材质图里各个色泽的面部贴图的权重。

![[UnrealEngine/MetaHuman/attachments/Pic_023.png]]

通过观察上面的base color混合信息我们可以发现，完整的metahuman 面部材质实际上会存储4套base color贴图，这四套贴图会按照人物的不同表情（面部动作）进行加权混合，具体的做法是以第一套base color作为基准，然后和其他贴图对它的RGB矢量的增量进行加权相加

$Basecolor_raw=Basecolor_raw+ω1*ΔBaseColor1+ω2*ΔBaseColor2+ω3*ΔBaseColor3$

而这个ω向量的来源正是上图左下角最后的一套表情（面部动作）。在角色蓝图上的材质实例里面，这正是Global Scalar参数里面这一大坨参数的来源。然后，我们就可以手动设置这些参数，或者用各种蓝图去自动设定这些参数（或者调用它的预设）去实现配合表情动画的皮肤材质的动画了。当然，需要说明的是这整个一套材质动画系统的变化是非常微妙细微的，只有在高配置环境下才能很好的体现出来，属于是一种“边际成本非常高”的美化功能。

![[UnrealEngine/MetaHuman/attachments/Pic_024.png]]

EPIC把相同的混合原理在法线信息上又如法炮制了一番。四套不同皮肤颜色还对应了各自的法线信息，按照上述原则进行混合，由于他们调用了相同的封装了表情标量参数的函数，所以对一个表情参数进行设置可以同时影响到漫反射颜色和法线信息。在这里EPIC还额外设置了一个微观法线信息的材质设定的节点，用于相机在极近距离下观察皮肤的毛孔等细节。当然此处我们可以看到通过一个面部遮罩，仅仅只是在嘴唇区域体现了皮肤的微表面法线细节。

![[UnrealEngine/MetaHuman/attachments/Pic_025.png]]

接下来的重点是面部妆容。目前来看Metahuman提供的可以调节妆容分为五块：底色，遮瑕膏色，腮红，眼影还有口红（翻译不周还敬请谅解，我对化妆道具一窍不通..）

![[UnrealEngine/MetaHuman/attachments/Pic_026.png]]

而本区域的标量数值实际上已经全部做成参数提供给了材质实例（Instance），我们在材质实例最上方的参数面板就能设置到。注意，眼影口红的mask是共享了一张贴图，区别是各个化妆品作用的区域在不同的颜色通道上。目前为止只占用了4个通道中的2个，也就是说理论上我们还可以继续开发，增加两个面部妆容的修改通道。当然啦，这样的设定给我的感觉就是允许我们在游戏里卖口红了..

好，到此为止我们看到了漫反射颜色和法线通道的情况，那么粗糙度呢？如下图所示，粗糙度拥有自己的贴图，通过贴图去给粗糙度的最大值和最小值来进行差值。然后面部皮肤的粗糙度信息会和妆容的粗糙度信息进行混合，然后和陶土材质（也就是mesh to metahuman的初始材质，现在我们先不用管这个）混合后进入roughness通道。

![[UnrealEngine/MetaHuman/attachments/Pic_027.png]]

需要特别指出的是，metahuman的面部所用的粗糙度贴图并不是一张单独的贴图，而是在已经有粗糙度贴图的基础上使用了一个比较冷门的UE引擎的”合成贴图“”功能，他把法线贴图的信息整合进了粗糙度贴图中。简要的说，就是在我们拥有一张粗糙度贴图的情况下，把3维的法线信息整合进粗糙度贴图。具体的原理请大家参考这篇文档，本文不再赘述

[Composite Texture | Unreal Engine 4.27 Documentation](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Textures/Composite/)

另外，specular也就是高光通道采用了一张cavity贴图（可以理解为一个锐化过后的AO贴图）作为基本信息，由于specular通道没有太多计算，所以就不详细展开了。

### 4.2.3 视觉资产——身体材质

相较于面部材质，身体材质相对简单一些（当然实际上也没简单到哪里去...）

身体材质的材质球存放在Content/MetaHumans/Common/Materials/M_BodySkin.uasset这个位置

![[UnrealEngine/MetaHuman/attachments/Pic_028.png]]

（可以在新页面打开放大）

我们同样从分析基本的漫反射颜色开始入手。身体的基本颜色信息是用了一张贴图呈现，这张贴图作用的范围是数字人锁骨以下的部位。

![[UnrealEngine/MetaHuman/attachments/Pic_029.png]]

![[UnrealEngine/MetaHuman/attachments/Pic_030.png]]

颜色信息有两个去处。第一个是通过和（metahuman编辑器web端应用的）黏土材质混合，进入漫反射通道。第二个去处是和散射修正函数进行混合，准确的说是颜色信息决定散射的程度，同时散射程度会被内衣内裤的遮罩覆盖，最终进入不透明度通道。

如图所示是黏土材质的效果

![[UnrealEngine/MetaHuman/attachments/Pic_031.png]]

另外我们要注意到，metahuman角色的内衣和内裤不是mesh，而是直接烘焙到漫反射颜色上去的。实际上，如果要把metahuman角色的内衣裤给扒下来的话，是需要艺术家们手绘这个细节的。这里epic给了人物加了一个双保险，不仅在漫反射颜色上绘制了内衣裤的颜色，还在法线信息上通过内衣裤mask的形式给人物增加了内衣裤的信息。当然，我们也可以动手改贴图，把角色内衣裤给扒下来。这里也提供一个用substance painter扒角色内衣和内裤的办法，它的核心原理是利用仿制图章工具用别处皮肤的信息覆盖掉内衣裤区域的漫反射颜色，粗糙度和法线信息。

[How to remove the underwear on your Metahuman - using Blender and Substance Painter. - YouTube](https://www.youtube.com/watch?v=cd_f0qZyOaA&t=6s)

我们再来关注法线通道上的信息。如下图所示：首先全身有一张全局性的法线贴图。上面我介绍过了内衣内裤的mask。这个mask是个多合一的遮罩，它包含了内衣裤区域，胸围和颈部结合部以及指甲区域。这个遮罩除了影响漫反射颜色以外，它同时也会把手伸到法线信息这里。在没有mask的地方，会展示皮肤的微观法线细节（这样我们可以在非常近的距离观察到皮肤的褶皱等效果），而在有内衣裤的地方，则展示内衣裤的法线信息（当然我们也可以像教程里面把内衣裤的法线信息给扒了）。

![[UnrealEngine/MetaHuman/attachments/Pic_032.png]]

值得注意的是，微观法线信息有两个贴图栏位，这是因为考虑到头身混合的时候，混合区容易出现接缝等非常明显的缺陷，为了防止出现这种生硬突兀的过渡，epic在那个内衣内裤的mask的绿色通道上给出了肩部区域的mask，他的值会从肩部头身接缝处从1过渡到胸肌/后背/两肋的0。这样我们就可以给头身接缝处一个能和头部mesh相匹配的法线贴图的同时和身体自身的宏观/微观法线信息无缝过渡。（这也是为什么我们最好不要不分RGB通道在内衣内裤mask贴图上乱改一气的原因）

最后如下图所示是粗糙度信息的计算过程。这个过程通过粗糙度贴图去对粗糙度的最大值和最小值进行线性差值，并且先后对头身邻接区的，内衣内裤区以及指甲区域做了粗糙度的覆盖性修正。

![[UnrealEngine/MetaHuman/attachments/Pic_033.png]]

值得一提的是，身体粗糙度贴图也是一张合成贴图。身体的法线贴图通过合成把更多的修正性细节整合到了粗糙度贴图里面。**不过这里似乎有个小BUG**：就是metahuman工程实际上没有提供现成的粗糙度贴图（按照UE文档里面使用法线-粗糙度合成结束需要预先拥有粗糙度信息的贴图），而这里如果我们把绿色通道关闭以后会发现贴图界面变成了一片黑。但是角色的粗糙度贴图事实上存在，我怀疑这可能是EPIC故意留的BUG。

![[UnrealEngine/MetaHuman/attachments/Pic_034.png]]

### 4.2.4 Metahuman所依赖的虚幻引擎支持系统

我们已经了解了metahuman是通过怎样的办法形成了一个写实的人体模型的。但是到目前为止，它还没有办法动起来，为了让metahuman发挥它的最大价值——动态效果，我们还需要了解一些支撑metahuman动作的虚幻引擎的功能。

首先是metahuman单个角色自身的蓝图，接下来是IK RIG反向动力学绑定蓝图, IK RETARGETER反向动力学重定向蓝图以及livelink技术。

####  MetaHuman蓝图

首先我们需要了解metahuman蓝图中引入的一种模块化角色模型的概念，即整个角色由多个采用相同（部分）骨骼的多个独立的分段的骨骼模型拼合而成。这样做的好处是：通过模块化我们可以省略很多模型的创建（尤其是身体模型），而只需要着重修改、雕刻那些差异化的部分（例如头部）。

![[Video_001.mp4]]

这个视频充分说明了什么是“模块化”角色的概念。通过模块化，我们可以像搭积木一样，复用角色的身体模块，从而可以把我们的美术重点放在角色那些容易引起注意的差异化的特点，这个特点可以是面部模型，也可以是其他的一些身体部分，甚至是饰品。如果我们按照传统的角色制作管线那样，一律把整个角色做成一个整体，那么每一个部件（肢体等）的变化都必然导致一个新的角色mesh需要被绑定改权重，这样就太浪费时间了。

![[UnrealEngine/MetaHuman/attachments/Pic_035.png]]

MetaHuman角色蓝图的Construction Script也就是构造脚本里，一个名为Enable Master Pose的函数起到了将body骨骼模型组件的动作传递到下面的同骨骼的骨骼模型组件里。

![[UnrealEngine/MetaHuman/attachments/Pic_036.png]]

如果我们继续点进去看，就可以发现，这个函数的作用就是在默认情况下（无单独指定的post process anim 蓝图和anim类）的情况下，把body组件的动画传递给它的子组件。当然，这里我们也强调了在没有post process anim蓝图或者anim类的情况下，因为在有对应动画处理蓝图的情况下，body骨骼动作传递给对应部件是在对于的动画处理蓝图里进行的，我们的head组件就是。

#### IK RIG和IK Retargeter

现在我们已经搞清楚了metahuman角色几何的组成，那么接下来要了解的就是怎么让角色动起来了！让角色动起来，最便捷的办法就是复用现成的动画。UE生态在UE4的Mannequin和UE5的Manny/Quin上积累了大量的动画，我们可以用重定向工具（Retargeter）将这些角色动作传递给metahuman。UE进入版本5.0以后，采用了新的retarget工具，也就是IK Retargter。

和过去只能允许在原骨骼上追加的新骨骼点的机制不同，UE5的IK Retargeter允许任意不同的骨骼结构之间进行重定向（至少在不同哺乳动物之间）。这个新工具非常类似于Houdini的Kinefx重定向机制——把骨骼切分为不同个IK链条，每个链条内部含有一些骨骼点。重定向系统分别传递IK链条的起止点，利用IK工具解决重定向问题。这样我们就可以hack掉骨骼结构不同的问题。

总而言之，IK Retargeter重定向可以用这张图简要的说明其原理

![[UnrealEngine/MetaHuman/attachments/Pic_037.png]]

此机制把角色的骨骼分为一段一段的IK链条，从IK链条的层面上分别重定向。

如图所示，站在前面的就是**Metahuman**的标准身体，身后的是**UE Mannequin**。我们需要为这两个角色的骨骼，各自建立一个IK RIG。例如在UE Mannequin的IK RIG中，我们把角色的左手部分，从_upperarm_l,lowerarm_l,hand_l_这三个骨骼按照顺序选取，建立一个IK链条，将其命名为_LeftArm_，然后在再到**Metahuman**的IK Rig中，把**metahuman**角色骨骼的左手，_upperarm_l,lowerarm_l,hand_l_这三个骨骼按照顺序选取，也建立了一个IK链条，将其命名为_LeftArm_。那么在IK Retargeter资产中，默认就会按名称匹配这两个链条，**Mannequin**的动作就会被通过IK传递的形式复制给**Metahuman**。需要注意的是，在源骨骼和目标骨骼的IK RIG中，每一块骨骼的名字无需匹配，我们只需要关系IK链条的名称能够对得上。此处**Metahuman**和**Mannequin**的骨骼点名称相同是一个巧合！

![[Video_005.mp4]]

#### Control Rig

一方面我们可以使用重定向来复用已有的动画资源，另一方面，我们可以利用ControlRig，也就是UE引擎的FK/IK操作工具来直接摆Metahuman的Pose，或者修改已有的动画，甚至是把已有的骨骼动画反向烘焙成ControlRig的动画。

由于Control Rig本身是UE引擎动画系统的内容，在这里我们就不介绍这项技术的细节([Control Rig in Unreal Engine | Unreal Engine 5.0 Documentation](https://docs.unrealengine.com/5.0/en-US/control-rig-in-unreal-engine/) 官方文档在此)。只是简要的讲一下怎么使用Control Rig去摆关键帧动画。

Control Rig主要是在Level Sequencer里使用，具体来说有两种用法

法一. 相当于在MAX/MAYA等DCC里手动创建关键帧，然后利用Level Sequencer插值，并且可以将插值的结果烘焙为Animation Sequencer

法二.在Level Sequencer里添加动画，同时，增加一个Control Rig轨道用于tweak已有的动画。具体来讲也有两种途径，第一种是把动画反向烘焙成Control Rig的动画，第二种是利用加性（Additive）轨道，利用Control Rig去在已有动画的关键帧上做一些修改。

对于Metahuman而言，Control Rig实际上是区分头部和身体的，而且头部和身体还各自有不止一个Control Rig

这里我们主要介绍三类，即 

- 身体的标准Control Rig(MetaHuman_ControlRig)
- 头部的面板Control Rig（Face_ControlBoard_CtrlRig）
- 简易Control Rig（simple_face_CtrlRig）_

身体Control Rig：

路径位于Content/MetaHumans/Common/Common/_MetaHuman_ControlRig_.uasset

这里首先放一个Control Rig 蓝图界面的基本介绍

![[Video_006.mp4]]

![[UnrealEngine/MetaHuman/attachments/Pic_038.png]]

注意我们前面说了，Control Rig既可以把控制器的动作烘焙成动画，也可以把动画反向烘焙成控制器动作，因此Control Rig蓝图的编辑界面也就有不同的入口。如上图蓝色线框所示，Forwards Solve正是我们想通过控制器去摆骨骼动作时的解算方向，请确保这个按钮显示Forwards Solve。而上图左上角3D渲染视口里红框内的Post Process Animation Blueprint也需要被启用才能在我们的3D预览窗口看到骨骼的动作，请确保它处于Enable状态（如图所示即为Enable状态）

![[UnrealEngine/MetaHuman/attachments/Pic_039.png]]

![[UnrealEngine/MetaHuman/attachments/Pic_040.png]]

如上图所示，所谓的解算方向在Control Rig的面条图上是有自己的入口的。

默认的身体Control Rig同时预制了FK/IK控制器，但是很显然我们是不能同时应用FK/IK的。我们需要在Rig Hierarchy中设置

![[UnrealEngine/MetaHuman/attachments/Pic_041.png]]

在Rig Hirerarchy底部，我们可以看见一系列FK_IK_Switch，我们可以在 右侧的Details面部里看到他们的值，将初值(Value_Initial)和现值（Value-Current）的单选框打上勾即启用IK控制模式，否则为FK控制模式。

如下图所示，角色的右手（对于角色而言）启用了IK，因此它的控制器是一个方框，而不像使用蓝色圆环FK控制器的左手

![[UnrealEngine/MetaHuman/attachments/Pic_042.png]]

具体的操作步骤视频里会进行进一步的介绍

![[Video_007.mp4]]

面部Control Rig：

面部的Control Rig蓝图有两套，一个是面板Control Rig工具，还有一个简易Control Rig。这两套工具都非常具有“直觉性”，我们可以直接看出这些控制器调节的是什么部位

它的使用方式还是和身体的Control Rig一样的，都是通过level Sequencer载入人物，然后在对应的面部Skeletal Mesh组件的track上点击加入Control Rig，其中_Face_ControlBoard_CtrlRig_是面板控制器，_simple_face_CtrlRig_是简易控制器

![[UnrealEngine/MetaHuman/attachments/Pic_043.png]]

对于手动制作面部动画，epic还提供了另一个管线：pose系统。这相当于直接利用Pose参数控制各个morph形态，从而我们只要从Pose文件夹里面挑选我们的面部动作，把他放到level sequencer关键帧上即可，而无需操作拥有者数十个控制器的control rig

他的具体做法是

i.打开Level Sequencer，新建Sequence

![[UnrealEngine/MetaHuman/attachments/Pic_044.png]]

ii.接着从outliner里拖拽角色进入sequencer窗口

![[UnrealEngine/MetaHuman/attachments/Pic_045.png]]

iii.接下来我们直接从左上角的animaiton面板上，点击pose按钮

![[UnrealEngine/MetaHuman/attachments/Pic_046.png]]

iv.初次打开Control Rig Pose面板，我们是没有metahuman的pose库目录的

![[UnrealEngine/MetaHuman/attachments/Pic_047.png]]

我们需要定位到这个位置

![[UnrealEngine/MetaHuman/attachments/Pic_048.png]]

v.接下来我们只要从Control Rig Pose菜单找到这个目录，进入任意一个Pose Library即可。通常我们使用Expression目录，这是预制的表情Pose

![[UnrealEngine/MetaHuman/attachments/Pic_049.png]]

vi.接下来，想用哪个表情，就直接选中该表情，勾选Key选项，点击Select Controls，然后再Paste Pose即可

![[UnrealEngine/MetaHuman/attachments/Pic_050.png]]

vii.最后结果

![[UnrealEngine/MetaHuman/attachments/Pic_051.png]]

另外，Metahuman还可以通过苹果智能手机进行面部动作捕捉，这个就是头部Mesh的Livelink技术，当然由于我手里暂时没有Iphone就介绍了，大家可以通过这篇文档了解，之后我会把livelink技术的介绍也补上

[Animating with Live Link | Epic Developer Community (epicgames.com)](https://dev.epicgames.com/documentation/en-us/metahuman/animating-metahumans-with-livelink-in-unreal-engine)

UE Metahuman的livelink技术的有点是：利用了高端消费级的硬件进行了面部动作的视频提取，无需像传统的面捕那样在自己的面部画上几十个定位点，这样有助于节约时间，从心理上说面捕演员更愿意接受。毕竟，谁愿意莫名其妙就把自己的脸画成麻疹脸呢？

## 4.3 Metahuman的UE引擎支持工具

为了更好的支撑Metahuman最终的游戏/Cinematic实现效果，我们还需要两个UE工具：Groom毛发系统和蓝图系统

我们先来说Groom毛发系统：

传统的游戏里头发的作法是把DCC里制作的毛发烘焙成HairCard，再对HairCard进行骨骼绑定，这是一种性价比很高的解决方案。因为我们不仅可以趁机烘焙一部分光影信息到毛发卡片的BaseColor信息中，我们还通过骨骼的运动抽象了大量毛发的运动，可谓是花小钱办大事。

![[UnrealEngine/MetaHuman/attachments/Pic_052.png]]

可是在质量要求非常变态的场景下（尤其是次世代PBR角色），HairCard就不够用了，只要HairCard制作的稍微有一丁点不自然，眼尖的用户就会看出问题。解决办法只有一个：那就是把HairCard做的变态的窄……窄到HairCard的宽度基本上已经等于原始毛发生成时引导线的作用距离……但此时工作的时间就大大增加了

那既然如此，我们为什么不直接把引导线及其附近的毛发直接迁移到引擎里呢？

Groom毛发系统能干了这个事情。由于毛发是从引导线向附近扩张生成的，所以其和以和动态光源交互并且取得较为真实的物理效果。

![[Video_008.mp4]]

由于Groom毛发系统的核心原理是直接引进引导线，所以角色身上其他的毛发，例如眉毛，睫毛，胡须，甚至体毛都能全部用Groom系统包办！与此同时，Groom系统还支持毛发的直接物理模拟，只需要在角色对应的Physical Assets里面给身体添加合适的碰撞体就行了(Metahuman以及自带物理资产，无需额外设置)。

![[UnrealEngine/MetaHuman/attachments/Pic_053.png]]

在默认情况下，Metahuman Creator将为我们设置好一切需要设置的毛发属性，包括毛发的颜色等材质信息。我们只需要在引擎里面按需设置好Groom系统的LOD切换比例即可

![[UnrealEngine/MetaHuman/attachments/Pic_054.png]]

完整的文档可以在这里获取: 
[Hair Rendering and Simulation in Unreal Engine | Unreal Engine 5.2 Documentation](https://docs.unrealengine.com/5.2/en-US/hair-rendering-and-simulation-in-unreal-engine/)

## 4.4 Metahuman的捏人工具（黑科技）

### Step 1.Metahuman插件的安装

在前面我们已经看到了，通过线上的Metahuman Creator我们可以在一个比较小的范围内塑造一个角色脸型。但是我们也注意到了，如果我们想做那种刻意临摹某个人（或者某个用户），如果我们就是想要还原用户的脸呢？

EPIC还准备了一个Mesh to Metahuman方案。简单的来说，这个工具允许我们把扫描过的3D头部模型通过一系列面部线条标记转变为Metahuman的角色脸部，同时，这个方案可以被降级为使用一张照片还原用户的脸部。我们挨个介绍一下。

首先我们要注意到这个工具本身不是Metahuman角色资产，而是一个单独的插件，在UE商城搜索Metahuman Plugin也就是Metahuman插件，这样我们才能启用这个功能

![[UnrealEngine/MetaHuman/attachments/Pic_055.png]]

安装完成后，启用，在你想要的目录右击，在菜单中选择Metahuman-Metahuman Identity

### Step 2.扫描的头部模型转为Metahuman角色

Mesh2Metahuman的核心要点在于通过识别面部的3D轮廓线，从而“精确”的确定角色头部的形状，在使用3D角色头部静态模型的时候，我们实际上需要固定相机，然后在该相机的视野中让AI自动看出并标记角色的面部轮廓线（我们会对轮廓线进行适当的修正）

![[Video_009.mp4]]

#### Bonus：单张照片还原角色面部

如果我们没有办法扫描用户的头部，那么怎么办呢？使用一些特定的Hack技巧，我们可以只使用一张面部照片完成用户面部的建模。

它的核心原理是：通过面部正脸照片猜出五官轮廓，通过轮廓还原脸部几何形状

![[Video_010.mp4]]

![[UnrealEngine/MetaHuman/attachments/Pic_056.png]]

最后呈现的效果质量

# 5. 怎样对Metahuman进行深度挖潜和改编？

## 5.1 爆改Metahuman的必要性

我非常荣幸的通知诸位，如果阁下现在就把Metahuman加入你们的游戏项目并且发行的话，那么以现在的用户量，八成会把Epic的Metahuman Creator服务器彻底挤爆，从而导致没有一个人能够用上，而且所有人都会发现，想要还原自己的数字人看上去总是和自己看镜子里的自己“差点意思”。究其所以就是因为人脸想要达到完全相似，不仅仅需要在几何形状上完美贴合，还需要皮肤的着色，尤其是五官和面部几个大线条附近的明暗着色要完美贴合实际情况。而我们目前的metahuman只是从照片中采集几何信息，并没能从照片中提取颜色和明暗信息。

其次，Metahuman角色头部LOD0骨骼非常复杂，Morph目标非常多，一个角色仅仅头部就要占据300~350MB左右的存储空间。那么如果我们要给每个用户都起一个头部，那么我们会花费多少存储空间呢？那么一个仅仅100万注册用户的头部模型，就需要约0.3 x 10^15 字节的容量来存储（1000块1T硬盘），这无论如何不能说是“划算的”吧。（当然，我们可以把成本转嫁给用户）

从美观的角度上说，Metahuman目前的造型功能有新意，但是造型存在比较大的几何限制，离预想中那种完美的脸部还原还有距离。更何况目前Metahuman脸部只有一种拓扑，特别是其眼部只有一种大双眼皮褶皱的造型。这将会严重限制元宇宙应用下对角色建模准确性。另外，角色的衣服组件也过于缺乏，图案也缺乏基本的几何变换功能。

最后，就是Metahuman目前服装非常受限，且一律没有布料模拟的效果。对于想要搞各种奇装异服用来卖的我们来说，这个问题不解决我们是没办法用好的Metahuman的。

## 5.2 我的Metahuman爆改管线：Metahuman-（Zbrush）-Houdini管线

经过一段时间的摸索，我基本打通了这样一条对Metahuman进行爆改的管线：

- 使用UE导出Metahuman FBX资源
- 利用Houdini Labs FBX Archive Import导入Metahuman的FBX文件
- 利用Zbrush雕刻对应的FBX资源
- 使用Zbrush的Attribute Copy节点把Zbrush修改后的FBX资源的点位置属性（P）读取到导入的FBX节点上，以确保其他属性不会丢失，并且重新计算点法线
- 利用Houdini的ROP FBX Character Export节点分别设置骨骼模型的皮和骨骼，进行导出
- 对于身体的Mesh，我们可以单独导入UE引擎，对于头部的Mesh，我们需要到对应角色的头部Skeletal Mesh Asset，以Import Base Mesh的形式导入（而不能独立导入头部的骨骼模型）
- 重新自动生成头部和身体的LOD
- 在角色蓝图中替换掉身体

那么，我们就举几个简单的例子来解释我们的管线的流程，以及强大的修改能力。

### 5.2.1 保持拓扑，修改体型

改Metahuman角色脸部是个技术活，首先呢这个角色的面部模型是带骨骼的，而且它的骨骼点非常多。如果说我们需要想让修改后的脸部模型继续能够套用UE面部表情动作的话，那么我们必须维持修改后的那是顶点数量和编号和我们UE里的这个角色的头部模型完全一样。如此，我们是不能够更改模型拓扑的。metahuman的面部表情动作大多数依赖于morph Target，而morph target必须保持拓扑以及顶点数量和序号的一致性。所以头部的修改在需要复用ue metahuman面部动作资源的情况下，只能改形态，不能改拓扑。

![[Video_011.mp4]]

在这个例子中，我们要注意几个特殊的关键点

- 我们要注意zbrush的polygroup，它是从obj文件的group参数里提取到各个面的分组将其转化为polygroup的
- 为此我们要灵活运用houdini的group工具，这里我们就利用了一个比较hack的方法，把group from name用于模型的材质名称
- polygroup是我们在zbrush里有效选取对象组成成分的有利武器，如果搭配上clip笔刷就更好了
- clip和mask笔刷对于雕刻复杂有机体结构非常关键，这里我们综合运用clip/mask在polygroup的加持下避免了眼球被改动

### 5.2.2 改拓扑

在一些情况下我们可以对metahuman身体的mesh进行非常深度的修改。这其中包括了拓扑结构的变更。当然，这样做也带来了一个很大的麻烦：UV和权重信息出现了破坏。

然而，在Houdini KineFX的动画框架下，这一切仍然可以处理。那么，我们这个改拓扑具体能改成什么样呢？

我觉得这个基本可以满足绝大部分修改需要了，这里我们就把metahuman数字人换成一个猪头。这个例子实际上是一个一石二鸟的功能，它既说明了身体可以被爆改，也说明了头部可以被爆改。

![[Video_012.mp4]]

## 5.3 Metahuman SDK：同人逼死官方

好了，到此为止我想我们对Metahuman的各种技术手段已经有了一个相对较深的认知了。可是我们作为Metahuman的上游用户，可能还是有一点缺憾，虽然现在面部动作可以用ControlRig做出来，但是具体到角色说话，那又怎么去解决让角色嘴巴动起来的问题呢？一种简单的办法是将音频文件进行语音音节拆分，把每个音节给匹配一个口部的动作。

在这个位置：/Content/MetaHumans/Common/Common/PoseLibrary/Face/Visemes

![[UnrealEngine/MetaHuman/attachments/Pic_057.png]]

我们可以看到EPIC已经为我们准备好的Visemes嘴唇部位动画的Pose预设，理论上说，我们只需要解析音频，将其翻译为音节然后映射到这些Control Rig的Pose上就行了。

那么如果我们不想自己去开发这套语音数字信号处理系统怎么办?（我们大多数人也不是通信和信号专业的），那么一款叫做MetahumanSDK的插件可以通过云服务帮你代为实现这个功能。

通过在UE商城里找到Metahuman SDK，这是一款第三方开发的Metahuman增强插件

![[UnrealEngine/MetaHuman/attachments/Pic_058.png]]

他可以实现两个功能

- 借助google或者AWS的云服务进行TTS文字转语音服务，并在UE引擎内实现接口
- 对语音进行分析，将其解析为Metahuman角色面部动作，并将结果发回客户端，也就是(Audio to Lip, ATL) 

这一套技术术语Metahuman SDK的Lip Sync技术栈，它的官方文档在这里

([[WIP] v1.5.5 - Metahuman SDK](https://docs.metahumansdk.io/metahuman-sdk/reference/metahuman-sdk-unreal-engine-plugin/wip-v1.5.5))

由于其官方文档是在Level Blueprint里完成的TTS/ATL请求，所以我们只需要进行一些迁移改造即可

当然Metahuman SDK目前还有一个小问题，就是ATL动画会导致头部丧失身体动画继承，这个问题我们将会在未来的更新中解决。

# 6. Metahuman的小总结

Metahuman技术是一项专业功能较强的人类角色实现工具，他主攻方向是写实类的3A风格的角色和角色动作，有其是面部动作。然而Metahuman采用了很多复杂的模块化技术，这导致它所使用的工具链延伸的宽度和深度都非常夸张，想要完整掌握Metahuman编辑生态需要花费不少时间。尽管从纸面上来说，Metahuman已经允许策划直接创作其想要的角色，但是事实上Metahuman Creator目前仍然是一套让策划用起来感觉不爽的工具。

Metahuman当前的面部造型和身体造型功能的自由度任然限制比较大，我们还无法达到随意捏脸捏身的地步。我们也不应完全把Metahuman作为实现元宇宙角色的唯一工具（至少我们需要对其进行魔改）。

并且Metahuman内部由于采用了模块化Skeletal Mesh技术，使得其系统里槽点众多，暗坑比比皆是，非常不适合大规模的应用。如果想要一套可以随意按照自己目的修改的数字人系统，那么Metahuman目前是达不到我们的期望的。更加正确的做法是参考Metahuman的设计思路，构建我们自己的数字人框架，使其具备以下基本功能

- 自己的多个头身模型模板
- 在固定UV或者其他DCC里才可见的参数前提下制作角色的精细化捏脸捏身体工具，以及美化工具
- 精细的面部rig用以支持面部捕捉，至少支持后处理，以在引擎里通过morph target curve的形式达成面部变形
- control rig和默认的pose仓库
- 服装布料模拟和毛发系统
- 视频面捕/身体动作捕捉，ATL嘴唇语音动画


# 参考文献

[MetaHuman文档 | Epic Developer Community (epicgames.com)](https://dev.epicgames.com/documentation/zh-cn/metahuman/metahuman-documentation)