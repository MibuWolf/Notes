---
tags:
  - ue unreal metahuman riglogic
---

# 1. 概述

关于MetaHuman的基本概念我们已经在[[1. 初探MetaHuman|初探MetaHuman]]中有过讨论在此不在赘述，本章将讨论基于MetaHuman如何实现自定义脸型。首先，我们要弄清楚MetaHuman是如何实现脸部及表情控制的，在了解了MetaHuman脸部实现方案后才能涉及到如何对其修改扩展以实现运行时自定义脸型等脸部特征以适配原本的表情变化。跟多关于MetaHuman面部表情方案的内容请查看[4. RigLogic|RigLogic]]。

# 2. 自定义脸型的方案探索

## 2.1 传统自定义脸方案

常规的捏脸方案无非就是使用骨骼和BlendShape(Morph)的方式控制捏脸和表情，不同的项目有这不同的方案。简单来说可以分为以下几类方案：骨骼捏脸+骨骼表情，Morph捏脸 + Morph表情，骨骼捏脸 + Morph表情，Morph捏脸 + 骨骼表情 等多种组合方案。骨骼顾名思义是针对骨骼的修改，其优势是简单高效易处理。可以通过对几个骨骼的调整完成对脸部某部分的修改自定义，但其不足也很明显，因为修改数据是基于骨骼的因此控制的细节都不如BlendShape(Morph) 方案。而 BlendShape(Morph) 方案则是基于顶点的修改因此其表现的细节度要高于基于骨骼的修改方案，但这也意味着此方案需要更高的开销。

例如，下图是某知名游戏的捏脸方案，其基本思路是通过调整骨骼并在运行时对表情动画进行修正以实现自定义脸下表情正确的效果：

![[UnrealEngine/MetaHuman/attachments/Pic_059.png]]

如上图所示，可以看到其基本思路是：用玩家自定义的数据修改基础脸(图中最下大眼Pose小眼Pose融合就是用玩家自定义数据修改默认脸数据)与经过映射修改的动画数据(图中右侧眼睛本地偏移映射到新Pose的偏移)融合得出最终的捏脸后表情数据。

## 2.2 MetaHuman方案探索

我们知道MetaHuman中对于面部表情的控制主要是通过[[4. RigLogic|RigLogic]]控制的，其基本原理是：每帧从[[3. DNA|DNA]]中读取出默认脸骨骼，通过多个与面部动作单元(AU)绑定的曲线输入计算出当前表情下每个相关骨骼的偏移信息并将偏移矩阵信息附加在默认脸骨骼上。当然对于其他细节的BlendShape，动画贴图等细节也是通过曲线控制的，至于自定义脸是否需要更改这些细节表现需要根据具体表现及品质等因此与美术同学共同协商决定，本文重点讨论通过调整骨骼的方式完成自定义脸部细节的控制。

至此，虽然MetHuman控制脸部表情动画的方案与传统做法中直接播放动画不同，但我们仍然能够借鉴[[2. 面部表情与自定义脸型#2.1 传统自定义脸方案|传统自定义脸方案]]中的实现捏脸功能。