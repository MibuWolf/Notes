---
tags:
  - ue unreal metahuman riglogic
---

# 1. 概述

关于MetaHuman的基本概念我们已经在[[1. 初探MetaHuman|初探MetaHuman]]中有过讨论在此不在赘述，本章将讨论基于MetaHuman如何实现自定义脸型。首先，我们要弄清楚MetaHuman是如何实现脸部及表情控制的，在了解了MetaHuman脸部实现方案后才能涉及到如何对其修改扩展以实现运行时自定义脸型等脸部特征以适配原本的表情变化。跟多关于MetaHuman面部表情方案的内容请查看[[3. RigLogic|RigLogic]]。

# 2. 自定义脸型的方案探索

## 2.1 传统自定义脸方案

常规的捏脸方案无非就是使用骨骼和BlendShape(Morph)的方式控制捏脸和表情，不同的项目有这不同的方案。简单来说可以分为以下几类方案：骨骼捏脸+骨骼表情，Morph捏脸 + Morph表情，骨骼捏脸 + Morph表情，Morph捏脸 + 骨骼表情 等多种组合方案。骨骼顾名思义是针对骨骼的修改，其优势是简单高效易处理。可以通过对几个骨骼的调整完成对脸部某部分的修改自定义，但其不足也很明显，因为修改数据是基于骨骼的因此控制的细节都不如BlendShape(Morph) 方案。而 BlendShape(Morph) 方案则是基于顶点的修改因此其表现的细节度要高于基于骨骼的修改方案，但这也意味着此方案需要更高的开销。

例如，下图是某知名游戏的捏脸方案，其基本思路是通过调整骨骼并在运行时对表情动画进行修正以实现自定义脸下表情正确的效果：

![[UnrealEngine/MetaHuman/attachments/Pic_059.png]]

如上图所示，可以看到其基本思路是：用玩家自定义的数据修改基础脸(图中最下大眼Pose小眼Pose融合就是用玩家自定义数据修改默认脸数据)与经过映射修改的动画数据(图中右侧眼睛本地偏移映射到新Pose的偏移)融合得出最终的捏脸后表情数据。

## 2.2 MetaHuman方案探索

我们知道MetaHuman中对于面部表情的控制主要是通过[[3. RigLogic|RigLogic]]控制的，其基本原理是：每帧从[[2. DNA|DNA]]中读取出默认脸骨骼，通过多个与面部动作单元(AU)绑定的曲线输入计算出当前表情下每个相关骨骼的偏移信息并将偏移矩阵信息附加在默认脸骨骼上。更多细节流程参见：

![[RigLogic运行时流程.canvas]]
当然对于其他细节的BlendShape，动画贴图等细节也是通过曲线控制的，至于自定义脸是否需要更改这些细节表现需要根据具体表现及品质等因此与美术同学共同协商决定，本文重点讨论通过调整骨骼的方式完成自定义脸部细节的控制。

至此，虽然MetHuman控制脸部表情动画的方案与传统做法中直接播放动画不同，但我们仍然能够借鉴[[4. 面部表情与自定义脸型#2.1 传统自定义脸方案|传统自定义脸方案]]中的实现捏脸功能。至此，就产生了我们基于MetaHuman捏脸的第一个方案：基于骨骼调整的捏脸方案。

### 2.2.1 基于骨骼调整的捏脸方案

结合传统游戏捏脸的基本思路，以及[[3. RigLogic#2.2 RigLogic运行流程|RigLogic运行流程]]，我们也可以将MetaHuman的捏脸分为两个步骤：对原始脸的修改和对表情数据的修改。这两部分也就相当于[[## 2.1 传统自定义脸方案|传统自定义脸方案]]流程图中左右两侧的操作：分别是对原始Pose的自定义调整/融合和将动画中骨骼便宜映射计算到新的Pose偏移。拆解到[[3. RigLogic#2.2 RigLogic运行流程|RigLogic运行流程]]中需要修改的部分流程如下所示：

![[RigLogic调整流程---基于骨骼调整的捏脸方案.canvas|基于骨骼调整的捏脸方案]]

由上图可知：对原始脸数据进行修改这一步骤比较简单，只需要我们记录到玩家对骨骼调整/修改的变换矩阵，在获取DNA中原始脸数据后对原始脸施加捏脸数据的矩阵变换即可。但是步骤二可能涉及到运行时对DNA中骨骼动画[[27. 稀疏矩阵行列压缩(Compressed Sparse Row Column Matrix)|压缩稀疏矩阵行]]的修改，其修改量将会是巨大的也可能存在性能压力，因此只将此方案列为备选方案。

### 2.2.2 基于控制器调整的捏脸方案

#### 基本思路

既然[[4. 面部表情与自定义脸型#2.2.1 基于骨骼调整的捏脸方案|基于骨骼调整的捏脸方案]]最大的问题和风险出在运行时修改表情动画数据，那么我们是否有一种不修改动画数据的实现捏脸的可行方案呢？答案是肯定的，通过分析[[2. DNA|DNA数据]]和[[3. RigLogic|RigLogic的实现原理]]，我们发现目前RigLogic对表情AU及表情动画修正的数据管理方式如下图所示(Maya中DNA查看插件)：

![[UnrealEngine/MetaHuman/attachments/Pic_067.png]]

按照这个结构，如果我们将捏脸控制器控制的骨骼数据也存储到DNA中，在不同AU叠加修正时也对捏脸数据进行修正，理论上就可以实现MetaHuman中的捏脸方案，且捏脸对表情的影响也可以由美术在Maya中控制。如下图所示：

![[UnrealEngine/MetaHuman/attachments/Pic_068.png]]

#### 具体实现

回顾[[2. DNA|DNA]]与[[DNA数据结构解析.canvas|DNA数据结构解析|DNA数据结构解析]]，我们发现要实现上图中的效果只需要稍微修改[[2. DNA|DNA]]数据。具体来说，我们只需要在原始控制数据(AU控制数据)后面增加我们自己定义的捏脸控制器数据，并在PSD修正数据中添加捏脸与表情的修正数据即可。

而在运行时，仍然由曲线控制面部表情的播放，而对捏脸的调整则通过新增的捏脸曲线控制。而捏脸与表情的修正数据也已被添加到PSD部分，也就是说捏脸后的表情修正已经被存在DNA中在运行时通过采样获取。该方案的修改流程如下图所示：

![[RigLogic调整流程---基于控制调整的捏脸方案.canvas]]

实际上该方案的核心改动变成了对DNA的修改，那么如何为Maya编写修改DNA的插件并在UnrealEngine中接入捏脸功能，我们将在[[5. 基于控制调整的捏脸方案|基于控制调整的捏脸方案]]中详细讨论。