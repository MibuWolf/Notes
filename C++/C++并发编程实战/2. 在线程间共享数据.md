---
tags:
  - cplusplus thread
---

# 1. 概述

将线程用作并行的关键优点之一，是在它们之间简单、直接地共享数据的潜力。 所以既然我们已经在上一章介绍了启动和管理线程，现在让我们来看看在多线程中共享数据的相关问题。

在多个线程中共享数据的问题本质上是多个线程对同一资源使用的问题。想象以下，你和朋友合租一个房间，房间内的物品都是公用的，午饭时间到了，如果你想用锅子烧个蛋炒饭而室友则想用锅子煮面，这个时候就会发生问题，亦或者说当你准备蛋炒饭材料时需要使用刀子，却正好发现刀子正在被室友用来切水果。刀子和锅子就像是多线程中共享的资源，当多个线程共享数据资源时就可能会出现潜在的问题，本章将讨论和分析线程之间共享数据的问题。

## 1.1 竞争条件

一般看来所有线程之间共享数据产生的问题都是由于修改数据导致的，如果两个线程都不会修改共享的数据资源，或者说共享数据资源是只读的，那也就不存在潜在的共享数据问题。如果多个线程对同一资源进行读/写时就会发生竞争条件(RaceCondition)，具体来说，就是此时的执行结果取决于系统对不同线程的指令调度执行顺序。因此当发生竞争条件时，最终结果可能是不正确的。

***注：只有在有修改共享数据时才会发生竞争条件，如果所有线程都是读取数据则不会有此问题出现。***

举个例子，可以更方便的理解竞争条件，考虑一个双向链表，它的每一个节点持有指向表中下一 节点和前一节点的指针。删除一个节点N的操作是：先将N的前一节点到N的链接更新为指向N的后一节点，然后将N的后一节点到N的链接更新为指向N的前一节点，最后删除节点N，如下图所示：

![[C++/C++并发编程实战/attachments/Pic_011.png]]

如果有两个线程同时使用一个双向链表，假设A线程要移除一个节点，B线程在读取列表数据，当A线程删除节点执行到b,c步骤时，B线程恰好读取节点数据，此时将得到错误数据甚至B线程程序崩溃，这就是竞争条件。

## 1.2 避免竞争条件

既然知道了竞争条件可能会导致最终结果不符合预期甚至导致崩溃，那么我们就应该想办法来避免竞争条件。最简单的方式就是用保护机制封装你的数据结构以确保修改数据的过程仅对修改线程可见，其他线程要么在修改前获取数据要么等待修改完成。另一种方案是修改数据结构的设计从而使得修改成为一系列不可分割的变更来完成，这通常被称为无锁编程(后续章节讨论)。

本章将对第一种方式进行讨论，即由C++标准提供的保护共享书的的最近本机制------互斥元(`mutex`)。

# 2. 互斥元(mutex)

互斥元(`mutex`)是C++提供的一种解决竞争条件的数据保护机制，在访问共享数据前锁定(`Lock`)与该数据相关的互斥元，当访问数据结构完成后解锁(`UnLock`)该互斥元。线程库会确保一旦一个线程已经锁定某个互斥元，所有其他试图锁定相同互斥元的线程必须等待，直到成功锁定了该互斥元的线程 解锁此互斥元。当然互斥元也并非完美无缺的，不当的接口封装，死锁或者保护过多或过少数据的形式都会或多或少存在问题，本章就将具体讨论和分析这些问题。

## 2.1 互斥元的基本用法

互斥元的用法很简单，一般在使用和操作共享数据时先通过互斥元`std::mutex`锁定，然后操作共享数据，操作完成后解锁，此时当其他线程操作同一数据时发现当前处于锁定状态则挂起等待直到解锁后才继续执行。作为替代，标准C ++库提供了`std:: lock_ guard`类模板，实现了互斥元的`RAII`惯用语法；它在构造时锁定所给的互斥元，在析构时将互斥元解锁，从而保证被锁定的互斥元始终被正确解锁。用法如下图所示：

![[C++/C++并发编程实战/attachments/Pic_012.png]]

❶处定义共享数据，❷处定义与此共享数据对应的互斥元，之后在所有操作共享数据的地方(❸❹)都使用互斥元对其进行限制，保证多线程下的共享数据安全。

***注： std::lock_guard本质上是在其构造函数中Lock互斥元，在析构函数中UnLock互斥元。***

上述示例中的共享数据和互斥元都是全局的，而实际上更加常见的做法是将互斥元和共享数据封装到同一个类中进行管理，互斥元和受保护的数据都作为类的私有成员。这样只需在操作和修改共享数据的接口函数中使用互斥元即可对共享数据进行的保护。

## 2.2 为共享数据精心组织设计代码

前面提到将互斥元和共享数据封装到一个类进行管理，但是仅做这样的设计是远远不够的，例如有一个接口虽然也被互斥元所约束，但其执行结果会将共享数据的指针或者引用返回出去，这无疑破坏了整个互斥结构设计，使得外部可以绕过互斥元接口直接访问共享数据。因此在封装共享数据时就对其精心设计接口和结构就显得尤为重要。

将共享数据的引用或地址传出，从而破坏互斥的情况很容易排查或者发现。只要在设计接口是遵循以下原则：**不要将受保护的数据指针或引用传递到锁的范围以外，无论是从函数返回值中返回，或者引用参数传出，还是以参数的形式传递给其他函数**。这一原则将帮助你有效的避免这一破话互斥的危险操作。一个反面的示例如下图所示：

![[C++/C++并发编程实战/attachments/Pic_013.png]]

## 2.3 发现接口中的固有竞争条件

如果只是将共享数据传出到互斥元保护以外破坏互斥结构还相对容易排查和发现，本节要讨论的是即使共享数据被互斥元严格保护着，仍然可能发生竞争条件的情况------接口中的竞争条件。如下图所示，是一个支持多线程访问的堆栈类的设计，它有`push()`压入数据，`pop()`弹出数据，`empty()`判断堆栈是否为空，`top()`返回第一个数据的副本(不是引用，就是为了避免上述章节中破坏互斥保护的情况)。

![[C++/C++并发编程实战/attachments/Pic_014.png]]

该类中的每个接口都被互斥元保护着，也没有任何接口返回该共享数据(堆栈)的引用或指针，但此类的设计仍然存在着竞争条件。如下图所示，在两个线程上分别操作该堆栈，明显可以看到因为两个线程的竞争关系会导致结果异常甚至崩溃。

![[C++/C++并发编程实战/attachments/Pic_015.png]]

在此情况下产生竞争关系的接口主要在于`top()`和`pop()`接口，此时就需要对接口设计进行改进，一个自然的想法就是在互斥元的保护下对两个接口的调用。将这两个可能产生竞争的接口合并成一个新的接口`pop()`弹出并返回最顶部数据。这里需要多一层的考虑如果从堆栈中弹出数据后返回数据前发生异常(***如果是值传递需要为临时变量开辟内存，因此可能内存不足而失败，如果先弹出数据再返回，则当内存不足时引发异常，但原始堆栈中的数据已弹出会发生数据丢失。因此可使用先获取堆栈顶部数据的引用或者智能指针再执行弹出操作的方式规避***)。因此改造后的堆栈接口如下，合并了引发竞争关系的`top()`和`pop()`接口。

![[C++/C++并发编程实战/attachments/Pic_016.png]]

上述对于`top()`和`pop()`接口示例的讨论表面，接口中有问题的竞争条件基本上是因为互斥锁锁定的功能操作颗粒度过小而引起的，互斥元的保护并没有能够覆盖到期望操作的整体。相反的互斥元保护的范围过大也会引发其他的问题，例如一个极端的例子，使用一个互斥元将堆栈的所有操作功能全部囊括(所有使用此堆栈任一接口的线程都必须等待其他线程没有使用任意接口时才能发生调用)。此时导致的后果将是共享数据(堆栈)操作是安全了，但是多线程的并行执行的优势大大降低，每个线程对此堆栈操作时将退化成为"单线程"执行方式，大大降低执行效率。另外如果对于一个给定的操作，需要两个挥着更多互斥元时，则可能存在死锁的问题将在下一节中讨论。因此在设计代码结构和接口时对于互斥元锁定操作的颗粒度大小和互斥元锁定方式就显得尤为关键。

## 2.4 死锁

谈到死锁就不得不提及经典的哲学家进餐问题，简单来说就是有两(多个)个哲学家一起进餐，左右手边各有一个餐刀和叉子，只有同时拿到刀叉才能成功进餐，如果一人拿到刀另一人拿到叉，除非有人放弃否则两人都无法正常进餐。对应到多线程中则是：两个/多个线程中的每一个都需要同时锁定两个(或多个)互斥元来执行一些操作，而当每个线程都锁定了一个互斥元而同时等待彼此的另一个互斥元时，两个线程因为相互等待而无法继续，这种情景被称为死锁。

为了避免死锁，常见的建议是始终使用相同的顺序锁定两个互斥元。(eg: 两个线程(哲学家)都以先刀后叉的顺序锁定互斥元，就可以规避死锁)。但此方法并不能解决所有情况，例如:对两个实例的数据进行交换，此时在不同线程中分别执行对两个实例的交换时就很难明确统一锁定顺序。所幸的是C++提供了一种简单的处理此情况的死锁问题：使用std::lock同时将两个互斥元锁定，如下图示例所示：

![[C++/C++并发编程实战/attachments/Pic_017.png]]

图中❶处调用`std::lock()`锁定两个互斥元，在❷❸处对这两个互斥元进行锁定(此处做出说明,使用一个新的变量`std::lock_guard`对两个互斥元锁定为的是在函数调用完成后自动解锁，后面的参数`std::adopt_lock`只是为了表示它们应沿用互斥元上原有的所有权关系，即此处`std::lock_guard`对象仅对其进行锁定但不会拥有其所有权)。另外此处的`std::lock()`会保证对两个互斥元同时锁定，如果其中一个无法锁定时也会对另一个释放锁定，从而对两个互斥元达到全有/全无的锁定关系。

虽然对互斥元的锁定是导致死锁的主要原因，但是并非所有的情况都可以同时对两个互斥元进行锁定(并非所有情况都适用`std::lock()`)，而且死锁的产生也并非仅仅限于对互斥元的锁定。例如：有A,B两个线程，A线程`joinB`，B线程`JoinA`也会因为A，B线程相互等待对方的结束从而产生死锁，又或者A线程依赖B线程中的某一事件`EventB`,而B线程中`EventB`事件的触发又依赖A线程的事件`EventA`,这种相互等待也可能会导致死锁。因此避免死锁问题的准则可以归纳为一个准则:如果有一个线程在等待你，那你这个线程就不要等待它。具体避免死锁的思路可以从以下几个准则思考解决：

- **避免嵌套锁**：该方法思路最为简单，如果你已经持有了一个互斥元锁，就不要再获取额外的其他锁。这样每个线程最多持有一个互斥元锁也就不会因为多线程多个锁的问题形成死锁。如果需要多个锁时，就使用`std::lock()`对多互斥元同时加锁，避免锁定A互斥元后再后续逻辑中又要锁定B互斥元形成死锁的风险。
    
- **在持有锁时，尽量避免调用外部代码**：该准确是上一准则的简单后续，其出发点我们不知道外部代码具体执行了什么操作，如果外部代码又有对互斥元加锁的调用则很可能违反**避免嵌套锁**的原则进而形成死锁。
    
- **以固定顺序获取锁**：前面也提到过当你不能用std::lock同时锁定多个互斥元时，在所有线程以固定的顺序锁定互斥元也可以有效的避免死锁。这也很好理解，所有线程都以同样顺序锁定互斥元时，如果A线程已经锁定了第一个互斥元，其他线程以同样顺序锁定时就必须等待A线程执行结束，也就不会再去锁定后续其他的互斥元，进而无法形成死锁条件了。
    
- **使用锁层次(层次锁)**：层次锁/锁层次本质上是一种特殊的固定顺序获取锁的方式。其思路是将互斥元分层，当代码试图对互斥元锁定时，如果当前有一个更低层次的互斥元被锁定则不允许锁定当前互斥元，从而保证所有线程都是按照从高往低的顺序锁定互斥元的。层次锁的实现及使用示例如下图所示：

![[C++/C++并发编程实战/attachments/Pic_018.png]]
![[C++/C++并发编程实战/attachments/Pic_019.png]]
![[C++/C++并发编程实战/attachments/Pic_020.png]]

- **将这些准则扩展的互斥元锁以外**：正如之前提到的形成死锁的原因不仅仅局限在锁，因此将上述准则扩展到其他可能导致死锁的情景中也是值得的。

## 2.5 使用std::unique_lock灵活锁定

利用`std::lock()`, `std::lock_guard()`使用上述规则设计你的代码来避免死锁，在很大程度上可以满足需求，但是有时却需要大的灵活性，标准库提供了`std::unique_lock`模板比`std::lock_guard`提供更多的灵活性，本节将介绍使用`std::unique_lock`灵活锁定。

`std::unique_lock`用法与`std::lock_gurad`类似但比其更加灵活(开销也更大)，`std::unique_lock`支持所有权转移，因此当你需要将互斥元所有权转移给调用者时可以使用`std::unique_lock`，如下图示例代码所示：

![[C++/C++并发编程实战/attachments/Pic_021.png]]

此外`std::unique_lock`还支持在析构函数执行前手动释放互斥元锁定，这对于某些复杂逻辑的某些分支很是有用，提前释放互斥元锁定可以减少其他线程等待时间提升执行效果。正如前面所说的使用`std::unique_lock`的开销比`std::lock_guard`要大，一般情况下使用`std::lock_guard`，除非你真的需要`std::unique_lock`的一些特性时才使用它。

## 2.6 锁定在恰当的颗粒度

前面讨论堆栈时提到过锁定颗粒度的问题，第一版堆栈类封装时因为锁定的颗粒度过小导致`top()`和`pop()`两个接口之间存在竞争条件。反过来锁定的颗粒度过大也会导致不必要的性能浪费，试想一下你对共享数据的操作仅在一个函数开始调用时执行(假设操作共享数据的时间是1ms)，如果使用`std::lock_guard()`对整个函数(整个函数的执行时间是10ms)进行了互斥元锁定，其中9ms的锁定时间内都不会操作共享数据，但是由于此时共享数据互斥元仍然处于锁定状态，其他线程仍然无法操作共享数据，这就是一个锁定颗粒度过大导致性能浪费的例子。

对于上述这种情况就比较适合使用`std::unique_lock`，它能够在不需要锁定共享数据的时候随时调用`unlock()`对其解锁，需要时再次加锁可以有效降低锁定颗粒度，如下图所示：

![[C++/C++并发编程实战/attachments/Pic_022.png]]

由此可见锁定的颗粒度不仅影响竞争条件，也会由于影响锁定时间进而影响其他线程的执行效率。**一般情况下，只应该以执行要求的操作所需的最小可能时间而去持有锁**。这也意味着耗时操作，如获取另一个锁，或者文件IO处理都不应该在持有锁的时候去执行，除非你真是想这么做。但是过犹不及，**如果你不能在操作的整个持续时间中持有所需要的锁，那么你就把自己包括在竞争条件中**。想想第一版堆栈接口的设计。

# 3. 用于共享数据保护的替代工具

上一节中提到了互斥元锁定的颗粒度，但是很多时候对需要锁定的颗粒度没有明确的界限，甚至根本就没有一个合适的颗粒度级别，在这种情况下就需要使用其他替代机制来代替互斥元锁定(`std::mutex`)的方式。

## 3.1 在初始化时包含共享数据

一种极端但又很常见的例子是共享数据只有在初始化时才需要并发访问的保护，在初始化完成后则不需要显示同步。例如游戏中获取材质/贴图时，多线程下获取某贴图，如果当前内存中没有此贴图则需要加载到内存，后续使用中基本不会修改贴图数据，但是在初次初始化加载时，在不同线程之间会存在竞争条件。对于这种问题一个自然而然的想法是每次获取资源前先用互斥元锁定，如果需要加载则加载资源否则正常执行并释放互斥元，如下图所示：

![[C++/C++并发编程实战/attachments/Pic_023.png]]

这样做在逻辑上固然可以达到保护该共享数据的目的，但是在实际上每个需要使用此数据的地方都会被锁定(即使它不需要初始化和修改此数据)，如果多线程中会频繁使用(读取)该共享数据，无疑会因为频繁锁定浪费不必要的等待时间(每次读取数据也必须锁定并等待其他线程执行完成)。从这一点来看似乎是锁定颗粒度过大了。

既然是锁定颗粒度过大，一个自然的想法就是仅在需要初始化时进行互斥元锁定，如下图所示，但这又会导致另一个问题：二次检测锁定(DoubleCheckedLocking)模式。

![[C++/C++并发编程实战/attachments/Pic_024.png]]

在未锁定❶处首次获取共享数据指针，如果为空则使用互斥元锁定，之后❷进行二次检查数据指针是否为空(为的是避免锁定过程中其他线程已经完成该共享数据的初始化)，如果仍然为空则开始加载初始化共享数据❸，最终使用该共享数据执行逻辑❹。一切看起来都是正常的完美的解决了对资源加载初始化的锁定问题，但是这里存在着一个隐藏的竞争条件即：❷和外部执行❸处的一个竞争，在A线程执行到❷时，可能另外的线程B刚刚实例化好共享数据`resource_ptr`，但是其内部所需的数据`some_resource`可能并未完全初始化完成。因此在A线程指向后续操作时可能因为共享数据`resource_ptr`被实例化但尚未完全初始化而导致运行失败甚至崩溃。这就是臭名昭著的二次检测锁定的隐藏竞争导致的问题。

C++标准委员会也发现这一重要情景，隐藏提供了`std::once_flag`和`std::call_once`来处理这种情况。当使用`std::callonce`来执行时，共享数据指针会被某一线程以完全同步的方式进行实例化和初始化，这样就保证了其安全性，此外使用`std::call_once`的性能比使用互斥元通常会更高。因此上述情景使用`std::call_once`改造后如下图所示：

![[C++/C++并发编程实战/attachments/Pic_025.png]]

## 3.2 保护很少更新的共享数据

独占锁/共享锁是boost库而非标准库的概念，其立基点在于处理频繁读取偶尔修改的情况。我们知道如果一个共享数据不会被修改那么他们是不会形成竞争条件的，多个线程可以随意读取。但是如果一个共享数据的修改频率非常低(例如:图书馆的书籍信息，平时只读只有在有新书入馆时才会更新书籍信息)，每次读取数据时仍然需要使用互斥元锁对其锁定(以避免概率极低的修改问题)则无疑会导致大量的性能浪费。Boost库中提供了共享锁(`boost::shared_lock`)的概念，独占锁可以简单理解成之前我们讨论的互斥元锁。共享锁是多个线程可以共享锁定数据(共享读取)其被限制的条件仅为当共享数据被独占锁定时(`std::mutex`)，也可以理解为如果数据被写入时共享锁不可锁定。独占锁则是检测被任意锁定时都不可以再做锁定操作，一个使用共享锁的简单示例如下图所示：

![[C++/C++并发编程实战/attachments/Pic_026.png]]

## 3.3 递归锁

在使用互斥元(`std::mutex`)进行锁定时，如果对以被锁定的互斥元加锁处理则会引发报错为定义的行为。但在某些特殊情况下我们可以需要一个线程对某互斥元进行多次锁定，另一线程要等到所有锁定释放后才可以继续执行。一个不太恰当的例子是：共享数据的`FucA`接口中调用了`FucB`接口，两个接口都会对共享数据进行修改，此时就需要使用递归锁将互斥元锁定两次，其他线程只有所在互斥元完全解锁后才可以继续操作。C++标准库提供了`std::recursive_mutex`来处理这种情况，只有`std::recursive_mutex`完全被释放后其他线程才可以继续执行。

***注：共享数据的FucA接口中调用了FucB接口的这种写法是不推荐的糟糕的接口设计方式，此处只是为了说明递归锁std::recursive_mutex的用法才以此为例。***